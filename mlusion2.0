# -*- coding: utf-8 -*-
"""mlusion_trial1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qz2cn_S5C_QxZ6x3cj5RpaWtuG_HjpAb
"""

!pip install -q kaggle

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')

import zipfile

zip_path = '/content/drive/MyDrive/TY_263/depression_data.zip'  # Update if your zip name is different
extract_path = '/content/depression_data'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

import os
os.listdir(extract_path)

import pandas as pd

file_path = extract_path + '/Depression-Dataset.csv'
df = pd.read_csv(file_path)

df.head()

#data cleaning
df.info()
df.isnull().sum()

#drop files
df = df.dropna()

print(df.columns)

#histogram visualization
import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(df['DEPRESSED'], kde=True)
plt.title("Depression Score Distribution")
plt.show()

X = df.drop(columns=['DEPRESSED'])
y = df['DEPRESSED']

#splitting dataset into training and testing
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

"""Training- Logistic Regression

"""

df_encoded = pd.get_dummies(df, drop_first=True)


X = df_encoded.drop(columns=['DEPRESSED'])
y = df_encoded['DEPRESSED']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()
log_model.fit(X_train, y_train)


log_preds = log_model.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay


print("Logistic Regression Results:")
print(classification_report(y_test, log_preds))

#confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix(y_test, log_preds), display_labels=log_model.classes_)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

"""Training- Random Forest

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, ConfusionMatrixDisplay


rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)


rf_preds = rf_model.predict(X_test)


print(" Random Forest Classifier Results:")
print(classification_report(y_test, rf_preds))


disp = ConfusionMatrixDisplay.from_predictions(y_test, rf_preds, cmap='Greens')
disp.ax_.set_title("Confusion Matrix - Random Forest")
plt.show()

"""Visualization of Logistic Regression and Random Forest with ROC curve"""

from sklearn.metrics import roc_curve, auc


log_probs = log_model.predict_proba(X_test)[:, 1]
rf_probs = rf_model.predict_proba(X_test)[:, 1]


log_fpr, log_tpr, _ = roc_curve(y_test, log_probs)
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)

log_auc = auc(log_fpr, log_tpr)
rf_auc = auc(rf_fpr, rf_tpr)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.plot(log_fpr, log_tpr, label=f'Logistic Regression (AUC = {log_auc:.2f})', color='blue')
plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.2f})', color='green')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line

plt.title('ROC Curve Comparison')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#choosing the best model
import joblib

joblib.dump(log_model, 'logistic_model.pkl')

"""Testing"""

import joblib

model = joblib.load('logistic_model.pkl')

from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f" Final Test Accuracy: {acc * 100:.2f}%")

sample = X_test[0].reshape(1, -1)
prediction = model.predict(sample)

print("Prediction:", "Depressed" if prediction[0] == 1 else "Not Depressed")

#confusion matrix
from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Purples')
plt.title("Confusion Matrix - Final Model")
plt.show()

#feature comparison
import pandas as pd

importances = rf_model.feature_importances_
feat_names = X.columns

feat_df = pd.DataFrame({'Feature': feat_names, 'Importance': importances})
feat_df.sort_values('Importance', ascending=True).tail(10).plot.barh(x='Feature', y='Importance', legend=False)
plt.title("Top 10 Important Features")
plt.show()
